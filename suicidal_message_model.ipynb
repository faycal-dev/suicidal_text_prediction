{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53634799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a102ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my life is meaningless i just want to end my l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muttering i wanna die to myself daily for a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work slave i really feel like my only purpose ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i did something on the 2 of october i overdose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel like no one cares i just want to die ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  intention\n",
       "0  my life is meaningless i just want to end my l...          1\n",
       "1  muttering i wanna die to myself daily for a fe...          1\n",
       "2  work slave i really feel like my only purpose ...          1\n",
       "3  i did something on the 2 of october i overdose...          1\n",
       "4  i feel like no one cares i just want to die ma...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"archive/twitter-suicidal_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6273c0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet        0\n",
       "intention    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa8ce1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3998, 5121)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data[\"intention\"] == 1]),len(data[data[\"intention\"] == 0])\n",
    "# the dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d697391b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>intention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>i wish i got to watch it with you i miss you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>i want to go to promote gear and groove but u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>oh manwas ironing fave top to wear to a meetin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>sadly though i ve never gotten to experience t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>wonders why someone that u like so much can ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>if you want you can always talk to me</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>people don t die from suicide they die from sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>she finally let go of her fake smile and tears...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9108</th>\n",
       "      <td>wil could ever love the girl with scars</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9112</th>\n",
       "      <td>fake friends are like shadows they follow you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5121 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  intention\n",
       "3325   i wish i got to watch it with you i miss you ...          0\n",
       "3326   i want to go to promote gear and groove but u...          0\n",
       "3327  oh manwas ironing fave top to wear to a meetin...          0\n",
       "3328  sadly though i ve never gotten to experience t...          0\n",
       "3329  wonders why someone that u like so much can ma...          0\n",
       "...                                                 ...        ...\n",
       "9103              if you want you can always talk to me          0\n",
       "9104  people don t die from suicide they die from sa...          0\n",
       "9106  she finally let go of her fake smile and tears...          0\n",
       "9108           wil could ever love the girl with scars           0\n",
       "9112  fake friends are like shadows they follow you ...          0\n",
       "\n",
       "[5121 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"intention\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a34b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ab7476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff57548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9693a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = []\n",
    "    for i in range(len(text)):\n",
    "        words = text[i].split()\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        words = [w.translate(translator) for w in words]\n",
    "        words = [wl.lemmatize(w.lower()) for w in words if not w in stopwords.words('english')]\n",
    "        sentence = \" \".join(words)\n",
    "        sentence = re.sub('[^a-zA-Z0-9]', ' ', sentence)\n",
    "        cleaned_text.append(sentence)\n",
    "    return np.array(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22558a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[\"tweet\"])\n",
    "x = clean_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a066dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(data[\"intention\"])\n",
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4393036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9119,), (9119,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e027bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d44fb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token='<unknown>')\n",
    "tokenizer.fit_on_texts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f55fcee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the vocab size is 22624\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f'the vocab size is {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1560618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9876,\n",
       " 208,\n",
       " 14,\n",
       " 613,\n",
       " 70,\n",
       " 5,\n",
       " 305,\n",
       " 254,\n",
       " 2917,\n",
       " 10,\n",
       " 50,\n",
       " 378,\n",
       " 109,\n",
       " 131,\n",
       " 329,\n",
       " 91,\n",
       " 47,\n",
       " 319,\n",
       " 218,\n",
       " 409,\n",
       " 5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tokenizer.texts_to_sequences(x)\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d69fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the maximum length of a sentence is 2147 in the index 6710\n"
     ]
    }
   ],
   "source": [
    "max_lenghth = 0\n",
    "index = None\n",
    "for i in range(len(x)):\n",
    "    if (len(x[i]) > max_lenghth):\n",
    "        max_lenghth = len(x[i])\n",
    "        index = i\n",
    "print(f\"the maximum length of a sentence is {max_lenghth} in the index {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ab6c6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet        my diary log as of so far okay my first time w...\n",
       "intention                                                    1\n",
       "Name: 6710, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[6710]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b7f4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# we will make the max_length 100 so it learn faster\n",
    "max_lenghth = 100\n",
    "x = pad_sequences(x, padding='post',maxlen=max_lenghth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "537a8e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9876,  208,   14,  613,   70,    5,  305,  254, 2917,   10,   50,\n",
       "        378,  109,  131,  329,   91,   47,  319,  218,  409,    5,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10d259e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9119, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1059d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "905b845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "815f29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(vocab_size, 50, input_length=x.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afe55ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4914e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00d6696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "107/107 [==============================] - 31s 290ms/step - loss: 0.0312 - accuracy: 0.9884\n",
      "Epoch 2/5\n",
      "107/107 [==============================] - 28s 261ms/step - loss: 0.0313 - accuracy: 0.9896\n",
      "Epoch 3/5\n",
      "107/107 [==============================] - 28s 266ms/step - loss: 0.0234 - accuracy: 0.9911\n",
      "Epoch 4/5\n",
      "107/107 [==============================] - 28s 264ms/step - loss: 0.0623 - accuracy: 0.9883\n",
      "Epoch 5/5\n",
      "107/107 [==============================] - 28s 265ms/step - loss: 0.0324 - accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29993a04df0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fc81a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 4s 51ms/step - loss: 0.3269 - accuracy: 0.8961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3269117772579193, 0.8960526585578918]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c100593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n",
    "model.save_weights(\"model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd413e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    text = clean_text(text)\n",
    "    text = tokenizer.texts_to_sequences(text)\n",
    "    text = pad_sequences(text, padding='post',maxlen=max_lenghth)\n",
    "    prediction = model.predict(text)\n",
    "    if prediction > 0.5:\n",
    "        print(\"this is a suicidal text\")\n",
    "    else:\n",
    "        print(\"this is not a suicidal text\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74936cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a suicidal text\n"
     ]
    }
   ],
   "source": [
    "test_string = ['i feel like no one cares i just want to die i am not happy']\n",
    "predict(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64c8bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is not a suicidal text\n"
     ]
    }
   ],
   "source": [
    "test_string2 = ['messi is leaving to paris and this is very sad for me i want him to stay']\n",
    "predict(test_string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f8a5cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a suicidal text\n"
     ]
    }
   ],
   "source": [
    "test_string3 = ['the last month i overdose i was near dead']\n",
    "predict(test_string3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bf73c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is not a suicidal text\n"
     ]
    }
   ],
   "source": [
    "test_string4 = ['the last month i played football and hurt my self for 2 weeks']\n",
    "predict(test_string4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e41cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
